{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b541b1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import required libraries\n",
    "import re         # For regular expressions (text tokenization)\n",
    "import requests   # For downloading the corpus\n",
    "import gzip       # For decompressing the downloaded corpus\n",
    "import io         # For handling byte streams\n",
    "import math       # For mathematical operations (log, exp)\n",
    "import random     # For random number generation\n",
    "from collections import defaultdict  # For efficient dictionary operations\n",
    "import pickle, os # For saving and loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bba523d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, torch, torch.nn as nn\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "docs = [\n",
    "    'Movies are fun for everyone.',\n",
    "    'Watching movies is great fun.',\n",
    "    'Enjoyed a great movie today.',\n",
    "    'Research is interesting and important.',\n",
    "    'Learning math is very important.',\n",
    "    'Science discovery is interesting.',\n",
    "    'Rock is great to listen to.',\n",
    "    'Listen to music for fun.',\n",
    "    'Music is fun for everyone.',\n",
    "    'Listen to folk music.'\n",
    "]\n",
    "\n",
    "labels = [1, 1, 1, 3, 3, 3, 2, 2, 2, 2]\n",
    "num_classes = len(set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf1bf6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return re.findall(r\"\\w+\" , text.lower())\n",
    "\n",
    "def get_vocabulary(texts):\n",
    "    tokens = {token for text in texts for token in tokenize(text)}\n",
    "    return {word: idx for idx, word in enumerate(sorted(tokens))}\n",
    "\n",
    "vocabulary = get_vocabulary(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d40cf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_to_bow(doc, vocabulary):\n",
    "    tokens = set(tokenize(doc))\n",
    "    bow = [0] * len(vocabulary)\n",
    "    for token in tokens:\n",
    "        if token in vocabulary:\n",
    "            bow[vocabulary[token]] = 1\n",
    "    return bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ba362d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = torch.tensor(\n",
    "    [doc_to_bow(doc, vocabulary) for doc in docs],\n",
    "    dtype=torch.float32\n",
    ")\n",
    "\n",
    "labels = torch.tensor(labels, dtype=torch.long) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1cb1052",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(vocabulary)\n",
    "hidden_dim = 50\n",
    "output_dim = num_classes\n",
    "\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleClassifier(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "627a8aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=0.01)\n",
    "\n",
    "for step in range(3000):\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(model(vectors), labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ffaec0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening to rock music is fun.: Music\n",
      "I love science very much.: Science\n"
     ]
    }
   ],
   "source": [
    "new_docs =[\n",
    "\"Listening to rock music is fun.\",\n",
    "\"I love science very much.\"]\n",
    "\n",
    "class_names = [\"Cinema\", \"Music\",\"Science\"]\n",
    "new_doc_vectors = torch.tensor([doc_to_bow(new_doc, vocabulary) for new_doc in new_docs], dtype=torch.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(new_doc_vectors)\n",
    "    predicted_ids = torch.argmax(outputs, dim=1) + 1\n",
    "\n",
    "for i, new_doc in enumerate(new_docs):\n",
    "    print(f'{new_doc}: {class_names[predicted_ids[i].item() - 1]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
